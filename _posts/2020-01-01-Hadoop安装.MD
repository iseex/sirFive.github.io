---
layout: post
title: "Hadoop安装"
date: 2020-01-01
description: "分布式安装、全分布式安装、高可用模式安装"
tag: Hadoop
---
### 1.hadoop伪分布式的安装
#### 1.jdk的安装
1.安装jdk  
![jdk的安装](/images/article/hadoop/伪分布式/1jdk安装.jpg "jdk的安装")  
2.配置jdk环境变量  
![jdk环境变量配置](/images/article/hadoop/伪分布式/2jdk.jpg "jdk环境变量配置")  
![jdk环境变量配置](/images/article/hadoop/伪分布式/3jdk.jpg "jdk环境变量配置")  
![jdk环境变量配置](/images/article/hadoop/伪分布式/4jdk.jpg "jdk环境变量配置")
#### 2.免秘钥登录配置
配置目的：避免访问节点时每次都需要输入账号密码。  
![免秘钥配置](/images/article/hadoop/伪分布式/5免秘钥.jpg "免秘钥配置")  
![免秘钥配置](/images/article/hadoop/伪分布式/6免秘钥.jpg "免秘钥配置")  
配置成功后会在.ssh目录下多一个公钥的文件。  
![免秘钥配置](/images/article/hadoop/伪分布式/7免秘钥.jpg "免秘钥配置")
#### 3.hadoop环境变量配置
![hadoop环境变量配置](/images/article/hadoop/伪分布式/8hadoop环境变量.jpg "hadoop环境变量配置")
#### 4.hadoop的jdk环境变量
修改hadoop-env.sh、mapred-env.sh、yarn-env.sh的jdk配置，不用它默认的。  
![hadoop的jdk环境变量](/images/article/hadoop/伪分布式/9hadoop的jdk环境变量.jpg "hadoop的jdk环境变量")
#### 5.配置主节点
在core-site.xml配置主节点。  
![配置主节点](/images/article/hadoop/伪分布式/11伪分布式配置主节点.jpg "配置主节点")
#### 6.配置副本数
在hdfs-site.xml中配置副本数，因为是伪分布式安装，所以副本只有一个。  
![配置副本数](/images/article/hadoop/伪分布式/12配置副本数.jpg "配置副本数")
#### 7.配置从节点
在slaves文件中配置从节点，因为伪分布式安装，所以从节点也是服务器自己。  
![配置从节点](/images/article/hadoop/伪分布式/13配置从节点.jpg "配置从节点")
#### 8.配置secondaryNameNode
在hdfs-site.xml中配置。  
![配置secondaryNameNode](/images/article/hadoop/伪分布式/14配置secondaryNameNode.jpg "配置secondaryNameNode")
#### 9.配置临时目录
在core-site.xml中配置临时目录，用来存放nameNode，dataNode和nameSecondary的文件。如nameNode中存放edit_log，fsimage等；dataNode存放上传的文件等。  
![配置临时目录](/images/article/hadoop/伪分布式/15配置临时目录.jpg "配置临时目录")
#### 10.格式化生成fsimage
![格式化生成fsimage](/images/article/hadoop/伪分布式/16格式化生成fsimage.jpg "格式化生成fsimage")  
格式化成功后会在临时目录下生成dfs目录和其子目录name的子目录中生成fsimage文件。  
![格式化生成fsimage](/images/article/hadoop/伪分布式/17格式化成功标识.jpg "格式化生成fsimage")
#### 11.启动集群
会先后启动nameNode、dataNode、secondaryNameNode。  
![启动集群](/images/article/hadoop/伪分布式/18启动集群.jpg "启动集群")
#### 12.可视化界面
登录地址：http://192.168.146.132:50070（登录不上，关闭Linux的防火墙试试）。  
![可视化界面](/images/article/hadoop/伪分布式/19可视化界面.jpg "可视化界面")
#### 13.文件上传hadoop
创建文件上传的路径。  
![文件上传的路径](/images/article/hadoop/伪分布式/20创建文件上传的路径.jpg "文件上传的路径")  
上传文件：hdfs dfs -put
![上传文件](/images/article/hadoop/伪分布式/21文件上传.jpg "上传文件")  
上传过程中,可视化界面的显示如下：  
![上传过程中](/images/article/hadoop/伪分布式/22上传过程中.jpg "上传过程中")  
上传完成可以看到，可视化界面中有两个block，因为系统默认一个block的大小是128M，而我上传的文件是170M，所以分成了两块。  
![上传完成](/images/article/hadoop/伪分布式/23上传完成.jpg "上传完成")
### 2.配置的代码
#### 1.免秘钥配置
```
ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa
cat ~/.ssh/id_dsa.pub >> ~/.ssh/authorized_keys
```
#### 2.core-site.xml
```
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://ip(或者别名):9000</value>
    </property>
    <property>
        <name>hadoop.tmp.dir</name>
        <value>/var/myfile/hadoop/local</value>
    </property>
```
#### 3.hdfs-site.xml
```
    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>
    <property>
        <name>dfs.namenode.secondary.http-address</name>
        <value>ip(或者别名):50090</value>
    </property>
```
### 3.hadoop全分布式的安装
#### 1.安装前的准备
1.同步所有服务器的时间  
![同步所有服务器时间](/images/article/hadoop/全分布式/1同步所有服务器时间.PNG "同步所有服务器时间")  
2.所有节点安装jdk  
![所有节点安装jdk](/images/article/hadoop/全分布式/2.所有节点安装jdk.PNG "所有节点安装jdk")  
3.关闭所有服务器防火墙 
![关闭所有服务器防火墙](/images/article/hadoop/全分布式/3.关闭所有服务器防火墙.PNG "关闭所有服务器防火墙")  
4确认home目录下有没有没有.ssh文件，没有要登录  
![home下没有.ssh要登录](/images/article/hadoop/全分布式/4.home下没有.ssh要登录.PNG "home下没有.ssh要登录")
#### 2.主节点免秘钥登录配置
1.主节点配置免秘钥  
![主节点配置免秘钥](/images/article/hadoop/全分布式/5.主节点配置免秘钥.PNG "主节点配置免秘钥")  
2.分发主节点公钥给从节点  
![分发主节点公钥给从节点](/images/article/hadoop/全分布式/6.分发主节点公钥给从节点.PNG "分发主节点公钥给从节点")  
3.从节点追加主节点公钥到认证文件
![从节点追加主节点公钥到认证文件](/images/article/hadoop/全分布式/7.从节点追加主节点公钥到认证文件.PNG "从节点追加主节点公钥到认证文件")
#### 3.环境配置
1.修改hadoop的jdk环境变量
![修改hadoop的jdk环境变量](/images/article/hadoop/全分布式/8.修改hadoop的jdk环境变量.PNG "修改hadoop的jdk环境变量")  
2.配置主节点和临时文件  
![配置主节点和临时文件](/images/article/hadoop/全分布式/9配置主节点和临时文件.PNG "配置主节点和临时文件")  
3.配置副本数和secNode  
![配置副本数和secNode](/images/article/hadoop/全分布式/10配置副本数和secNode.PNG "配置副本数和secNode")  
4.指定从节点  
![指定从节点](/images/article/hadoop/全分布式/11指定从节点.PNG "指定从节点")
#### 4.其它节点配置
1.将配置好的hadoop包分发到其它节点  
![将配置好的hadoop包分发到其它节点](/images/article/hadoop/全分布式/12将配置好的hadoop包分发到其它节点.PNG "将配置好的hadoop包分发到其它节点")  
2.配置所有的hadoop环境变量  
![配置所有的hadoop环境变量](/images/article/hadoop/全分布式/13配置所有的hadoop环境变量.PNG "配置所有的hadoop环境变量")
#### 5.启动
1.格式化主节点  
![格式化主节点](/images/article/hadoop/全分布式/14格式化主节点.PNG "格式化主节点")  
2.启动主节点的hadoop  
![启动主节点的hadoop](/images/article/hadoop/全分布式/15启动主节点的hadoop.PNG "启动主节点的hadoop")
#### 6.启动失败，重配
1.配置别名
![配置别名](/images/article/hadoop/全分布式/15配置别名.PNG "配置别名")  
![配置别名](/images/article/hadoop/全分布式/16配置别名.PNG "配置别名")  
![配置别名](/images/article/hadoop/全分布式/17配置别名.PNG "配置别名")  
2.重新分发公钥
![重新分发公钥](/images/article/hadoop/全分布式/18重新分发公钥.PNG "重新分发公钥")  
3.重新格式化，要删除所有节点的临时文件再格式化，否则versionID不一样  
![删除所有节点的临时文件](/images/article/hadoop/全分布式/19删除所有节点的临时文件.PNG "删除所有节点的临时文件")  
4.设置根目录  
![设置根目录](/images/article/hadoop/全分布式/20设置根目录.PNG "设置根目录")  
5.启动成功
![启动成功](/images/article/hadoop/全分布式/21启动成功.PNG "启动成功")